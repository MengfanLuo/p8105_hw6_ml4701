---
title: "HW6"
author: "Mengfan Luo"
date: "12/3/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(corrplot)
library(modelr)
library(mgcv)
#library(p8105.datasets)
#library(leaflet)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

### Data loading and cleaning

Data is loaded and cleaned. There's no missing data in the dataset. `babysex`, `frace`, `malform`, and `mrace` are converted to factors.

```{r}
birthweight_df = read_csv("data/birthweight.csv")
sum(is.na(birthweight_df))

birthweight_df = birthweight_df %>% mutate(
  babysex = factor(babysex, labels = c("male","female" )),
  frace = factor(frace, labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
  malform = factor(malform, labels = c("absent", "present")),
  mrace = factor(mrace, labels = c("White", "Black", "Asian", "Puerto Rican"))
  
) %>% 
  relocate(bwt)

```

### Variable selection and model contruction

Since all values in `pnumlbw` and `pnumsga` are 0, these variables are helpless in predicting baby's birth weight, thus is removed. Similar to `parity`, which only 3 samples have values other than 0.

Using `corrplot`, we can see the correlation between numeric variables. The outcome of interest `bwt` has a relatively strong correlation with `bhead`, `blength`, `gaweeks`, and `delwt`, so we want to include these variables in our model. We can also see that these variables are not correlated with each other, so we don't need to consider problem of colinearity.  Also, looking at the categorical variables, female and male baby may have difference in birth weight, so we also include `babysex`. Thus our model includes `bhead`, `blength`, `gaweeks`,`delwt` and `babysex`

```{r}
birthweight_df = birthweight_df %>% 
  select(-pnumlbw,-pnumsga,-parity)

birthweight_cor = birthweight_df %>% 
  select(-babysex, -frace, -malform, -mrace) 

corrplot(cor(birthweight_cor), type = "upper", diag = FALSE)

```

Model was fitted and we can see p values for all estimates of the coeficients are < 0.05. A plot of model residuals against fitted values was shown.

```{r}
fit = lm(bwt ~ bhead + blength+ gaweeks+ delwt+ babysex, data = birthweight_df)

fit %>% 
  broom::tidy() %>% 
  mutate(term = str_replace(term,"babysex","sex_")) %>% 
  select(term,estimate,p.value) %>% 
  knitr::kable(digits = 5)

birthweight_df %>% 
  modelr::add_predictions(fit) %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = pred, y = resid))+
  geom_point()+
  labs(
    title = "Model residuals against fitted values",
    x = "Fitted values", 
    y = "Residuals"
  )

```

From the plot, residuals seem not independent from the fitted values, which means we may need some additional variables or terms to have better prediction, such as interaction terms and high dimension terms.

### Model comparison

Additional 2 models were constructed as instructed.

We define:

`model 1: bwt ~ blength + gaweeks`,

`model 2: bwt ~ bhead + blength+ babysex + bhead*blength + bhead* babysex +\n blength* babysex + bhead * blength * babysex`

And the previous model as 

`model 0: bwt ~ bhead + blength+ gaweeks+ delwt+ babysex`

100 pairs of cross-validation sets were generated. RMSE for each test set were calculated and reflected in the boxplots for each model.


```{r}
set.seed(1)

cv_df = crossv_mc(birthweight_df,100)

cv_df = cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test,as_tibble)
  )

cv_df = cv_df %>% 
  mutate(
    mod0 = map(.x = train,~lm(bwt ~ bhead + blength+ gaweeks+ delwt+ babysex, data = .x)),
    mod1 = map(.x = train,~lm(bwt ~ blength+ gaweeks, data = .x)),
    mod2 = map(.x = train,~lm(bwt ~ bhead + blength+ babysex + bhead*blength + bhead* babysex + blength* babysex + bhead * blength * babysex, data = .x))
    ) %>% 
  mutate(
    rmse_mod0 = map2_dbl(.x  = mod0,.y = test,~rmse(model = .x, data = .y)),
    rmse_mod1 = map2_dbl(.x  = mod1,.y = test,~rmse(model = .x, data = .y)),
    rmse_mod2 = map2_dbl(.x  = mod2,.y = test,~rmse(model = .x, data = .y))
  )

cv_df = cv_df %>% 
  select(.id,starts_with("rmse")) %>% 
  pivot_longer(
    rmse_mod0:rmse_mod2,
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") 

cv_df %>% 
  group_by(model) %>% 
  summarize(mean_rmse = mean(rmse)) %>% 
  knitr::kable()

cv_df %>% 
  mutate(model = factor(model, label = c("model 0","model 1", "model 2"))) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_boxplot()+
  labs(
    title = "RMSE for 3 models generated",
    x = "Model",
    y = "RMSE")

```

From the table summary of rmse of each model and the boxplot, we can see `model 0` has the smallest average RMSE of `282.5508`, while `model 2` is similar but a bit larger. `model 3` has the largest RMSE as `332.2287`. This shows that `model 1` has the best prediction on `bwt`.











